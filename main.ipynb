{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b839d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db2196c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CCBmxcvLqmWxP3SwCqQGkX7B9PMpX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"get_news('South Korea')\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757021287, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_8bda4d3a2c', usage=CompletionUsage(completion_tokens=6, prompt_tokens=98, total_tokens=104, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI()\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "I have the following function\n",
    "\n",
    "`get_weather`\n",
    "`get_currecy`\n",
    "`get_news`\n",
    "\n",
    "All of them receive the name of a country as an arguemtn (i.e get_news('Spain))\n",
    "\n",
    "Please anser with the name of the function that you would like me to run.\n",
    "\n",
    "Please say nothing else, just the name of the functino with the arguemtns.\n",
    "\n",
    "Answer th following question: What is the capital of Korea?\n",
    "\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "\tmodel=\"gpt-4o-mini\",\n",
    "\tmessages=[{\n",
    "\t\t\"role\" : \"user\",\n",
    "\t\t\"content\" : PROMPT\n",
    "\t}]\n",
    "\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fed04fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"get_news('South Korea')\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message =response.choices[0].message.content\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7998b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "client = openai.OpenAI()\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "519b7133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ai():\n",
    "\t\tresponse = client.chat.completions.create(\n",
    "\t\t\tmodel=\"gpt-4o-mini\",\n",
    "\t\t\tmessages=messages\n",
    "\t\t)\n",
    "\t\tmessage = response.choices[0].message.content\n",
    "\t\tmessages.append({\n",
    "\t\t\t\"role\" : \"assistant\",\n",
    "\t\t\t\"content\" : message\n",
    "\t\t})\n",
    "\t\t# return message\n",
    "\t\tprint(f\"AI: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "524f680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hi\n",
      "AI: Hi again! What would you like to chat about?\n",
      "User: how you feel\n",
      "AI: I don’t have feelings, but I’m here to assist you! How can I help you today?\n",
      "User: what?  why you dont have feeling?\n",
      "AI: I’m an artificial intelligence, so I don’t experience emotions or feelings like humans do. My main purpose is to provide information and assistance based on your questions and needs. If you have any questions or need support with something, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\tmessage = input(\"Send a message to LLM...\")\n",
    "\tif message == 'quit':\n",
    "\t\tbreak\n",
    "\telse:\n",
    "\t\tmessages.append({\n",
    "\t\t\t\"role\" : \"user\",\n",
    "\t\t\t\"content\" : message\n",
    "\t\t})\n",
    "\t\tprint(f\"User: {message}\")\n",
    "\t\tcall_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe0189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b53fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
